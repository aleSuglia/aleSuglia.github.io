<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Alessandro Suglia</title>
    <link>https://alesuglia.github.io/</link>
    <description>Recent content in Home on Alessandro Suglia</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Feb 2018 18:56:13 -0500</lastBuildDate>
    
	<atom:link href="https://alesuglia.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Alexa Prize Challenge 2018</title>
      <link>https://alesuglia.github.io/projects/alexa_prize_2018/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/projects/alexa_prize_2018/</guid>
      <description>Contributed to the design of the conversational agent architecture and communication protocol. Designed the NLU pipeline composed of several state of the art NLP components for Named Entity Recognition, Entity Linking and Sentiment Analysis. In addition, the pipeline leverages an intent classifier based on a Deep Learning model trained on real conversations collected during the 2018 competitions. Responsible for the development of several bots able to retrieve information from Wikidata, Wikipedia and news articles.</description>
    </item>
    
    <item>
      <title>Ask Me Any Rating: A Content-based Recommender System based on Recurrent Neural Networks</title>
      <link>https://alesuglia.github.io/projects/amar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/projects/amar/</guid>
      <description>In this work we propose Ask Me Any Rating (AMAR), a novel content-based recommender system based on deep neural networks which is able to produce top-N recommendations leveraging user and item embeddings which are learnt from textual information describing the items.
A comprehensive experimental evaluation conducted on state of-the-art datasets such as MovieLens 1M and DBbook showed a significant improvement over all the baselines taken into account.
You can find more details about our approach in two of our papers:</description>
    </item>
    
    <item>
      <title>Contribution to the AllenNLP project</title>
      <link>https://alesuglia.github.io/projects/allennlp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/projects/allennlp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integrated Dialog bAbI&#43; dataset in ParlAI</title>
      <link>https://alesuglia.github.io/projects/parlai_babi_plus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/projects/parlai_babi_plus/</guid>
      <description>The aim of the present pull-request is to add a new world in ParlAI based on the recently proposed dataset bAbI+. bAbI+ is an extension of the bAbI Task 1 dialogues with everyday incremental dialogue phenomena (hesitations, restarts, and corrections) which model the disfluencies and communication problems in everyday spoken interaction in real-world environments. See [1], [2] for additional information about the dataset.</description>
    </item>
    
    <item>
      <title>Iterative Multi-document Neural Attention for Multiple Answer Prediction</title>
      <link>https://alesuglia.github.io/projects/imnamap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/projects/imnamap/</guid>
      <description>People have information needs of varying complexity, which can be solved by an intelligent agent able to answer questions formulated in a proper way, eventually considering user context and preferences. In a scenario in which the user profile can be considered as a question, intelligent agents able to answer questions can be used to find the most relevant answers for a given user.
In this work we propose a novel model based on Artificial Neural Networks to answer questions with multiple answers by exploiting multiple facts retrieved from a knowledge base.</description>
    </item>
    
    <item>
      <title>Schema-aware Translating Embeddings model</title>
      <link>https://alesuglia.github.io/projects/schema_transe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/projects/schema_transe/</guid>
      <description>We implemented a Torch Deep Learning model able to learn Knowledge Graph embeddings from knowledge base triples. We modified the original negative sampling procedure presented in the paper Translating Embeddings for Modeling Multi-relational Data by incorporating constraints derived from the Ontology schema in order to learn more effective and expressive representations.
https://github.com/aleSuglia/schema-transe</description>
    </item>
    
    <item>
      <title>Entertaining and Informative Open-domain Social Dialogue using Ontologies and Entity Linking</title>
      <link>https://alesuglia.github.io/publications/alexa_prize_2018/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/publications/alexa_prize_2018/</guid>
      <description>We describe our 2018 Alexa prize system (called ‘Alana’) which consists of an ensemble of bots, combining rule-based and machine learning systems. This paper reports on the version of the system developed and evaluated in the semifinals of the 2018 competition (i.e. up to 15 August 2018), but not on subsequent enhancements. The main advances over our 2017 Alana system are:
 a deeper Natural Language Understanding (NLU) pipeline; the use of topic ontologies and Named Entity Linking to enable the user to navigate and search through a web of related information; rendering Alana in part an interactive NL interface to linked information on the web; system generated clarification questions to interactively disambiguate between Named Entities as part of NLU; a new profanity &amp;amp; abuse detection model with rule-based mitigation strategies; response retrieval from Reddit.</description>
    </item>
    
    <item>
      <title>An automatic procedure for generating datasets for conversational recommender systems</title>
      <link>https://alesuglia.github.io/publications/convrecsys/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/publications/convrecsys/</guid>
      <description>Conversational Recommender Systems assist online users in their information-seeking and decision making tasks by supporting an interactive process with the aim of finding the most appealing items according to the user preferences. Unfortunately, collecting dialogues data to train these systems can be labour-intensive, especially for data-hungry Deep Learning models. Therefore, we propose an automatic procedure able to generate plausible dialogues from recommender systems datasets.</description>
    </item>
    
    <item>
      <title>Converse-Et-Impera: Exploiting Deep Learning and Hierarchical Reinforcement Learning for Conversational Recommender Systems</title>
      <link>https://alesuglia.github.io/publications/cei/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/publications/cei/</guid>
      <description>In this paper, we propose a framework based on Hierarchical Reinforcement Learning for dialogue management in a Conversational Recommender System scenario. The framework splits the dialogue into more manageable tasks whose achievement corresponds to goals of the dialogue with the user. The framework consists of a meta-controller, which receives the user utterance and understands which goal should pursue, and a controller, which exploits a goal-specific representation to generate an answer composed by a sequence of tokens.</description>
    </item>
    
    <item>
      <title>A deep architecture for content-based recommendations exploiting recurrent neural networks</title>
      <link>https://alesuglia.github.io/publications/amar/</link>
      <pubDate>Sun, 09 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/publications/amar/</guid>
      <description>In this paper we investigate the effectiveness of Recurrent Neural Networks (RNNs) in a top-N content-based recommendation scenario. Specifically, we propose a deep architecture which adopts Long Short Term Memory (LSTM) networks to jointly learn two embeddings representing the items to be recommended as well as the preferences of the user. Next, given such a representation, a logistic regression layer calculates the relevance score of each item for a specific user and we returns the top-N items as recommendations.</description>
    </item>
    
    <item>
      <title>Iterative multi-document neural attention for multiple answer prediction</title>
      <link>https://alesuglia.github.io/publications/imnamap/</link>
      <pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alesuglia.github.io/publications/imnamap/</guid>
      <description>People have information needs of varying complexity, which can be solved by an intelligent agent able to answer questions formulated in a proper way, eventually considering user context and preferences. In a scenario in which the user profile can be considered as a question, intelligent agents able to answer questions can be used to find the most relevant answers for a given user. In this work we propose a novel model based on Artificial Neural Networks to answer questions with multiple answers by exploiting multiple facts retrieved from a knowledge base.</description>
    </item>
    
  </channel>
</rss>